{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install chromadb\n",
        "%pip install load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new Chroma client with persistence enabled. \n",
        "persist_directory = \"db\"\n",
        "\n",
        "client = chromadb.PersistentClient(path=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from chromadb.utils import embedding_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Load variables from .env file into environment\n",
        "\n",
        "openai_key = os.environ.get('OPENAI_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using OpenAI Embeddings. This assumes you have the openai package installed\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=openai_key,\n",
        "    model_name=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new chroma collection\n",
        "openai_collection = client.get_or_create_collection(name=\"lake\", embedding_function=openai_ef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai_collection.add(\n",
        "    documents=[\"Tomatoes, onions, baby potoatoes, cabbage, cabbage leaves\", \"jolof rice\"],\n",
        "    metadatas=[{\"topic\": \"ingredients_list\"}, {\"topic\": \"favourite_recipes\"}],\n",
        "    ids=[\"id1\", \"id2\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = openai_collection.query(\n",
        "    query_texts=[\"recipies\"],\n",
        "    n_results=2\n",
        ")\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
